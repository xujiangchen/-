- [Hive](#hive)
  - [一、概述](#一概述)
    - [1.1 什么是hive](#11-什么是hive)
    - [1.2 什么是数仓](#12-什么是数仓)
    - [1.3 数仓和关系型数据库的区别](#13-数仓和关系型数据库的区别)
    - [1.4 ETL是什么](#14-etl是什么)
  - [二、Hive的工作原理](#二hive的工作原理)
    - [2.1 Hadoop](#21-hadoop)
    - [2.2 Hive的作用](#22-hive的作用)
    - [2.2 元数据](#22-元数据)
  - [三、Hive的数据模型](#三hive的数据模型)
    - [3.1 数据库](#31-数据库)
    - [3.2 表](#32-表)
    - [3.3 分区](#33-分区)
    - [3.4 分桶](#34-分桶)

# Hive

## 一、概述

### 1.1 什么是hive
hive的是定位是数据仓库（数仓），hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。

### 1.2 什么是数仓
顾名思义，是存储数据的地方，数仓**既不生产数据也不消费数据**，只是将数据存储在这个地方。各种数据源的数据通过ETL操作将数据加载到数仓，数仓中的这些数据又给具体业务决策的分析做支撑。

### 1.3 数仓和关系型数据库的区别

- 关系性数据库：
  - OLTP：on-line transaction processing，联机事务处理，主要是业务数据，需要考虑高并发、考虑事务
- 数据仓库：
  - OLAP：On-Line Analytical Processing，联机分析处理，重点主要是面向分析，会产生大量的查询，一般很少涉及增删改

当业务简单，数据量较少时，确实可以直接通过关系型数据库的SQL语法进行数据分析。但当业务越做越多，用户和数据量很庞大就会出现以下问题
- 数据分别存放在很多个不同的数据库，甚至存在于各种日志文件中，你要如何获取这些数据？
- 从各数据源中取出了你要的数据，但是发现格式不一样，或者数据类型不一样，你要怎么规范？
- 有一天你需要在业务系统查历史数据，但发现这些数据被修改过的，你要怎么办？
- 要跨集群关联各个不同业务系统的数据，要怎么做？怎么优化查询时间？

### 1.4 ETL是什么

数据从来源端经过抽取`extract`、转换`transform`、加载`load`至目的端的过程。通常来说ETL是一个固定名词，在实际业务中，ETL的顺序也是有可能进行转换的，在数仓中也经常存在ELT的操作顺序。

## 二、Hive的工作原理
![hive的工作原理](https://github.com/xujiangchen/Big-Data/blob/main/Hive/img/Hive%20work.png)

### 2.1 Hadoop
hadoop是分布式系统基础架构，它实现了一个分布式文件系统（HDFS）,hadoop中的数据都是以文件的格式存储在HDFS当中，hadoop本身也支持数据的分析和处理，但是比较复杂，通过手写java代码实现MapReduce进行数据处理，每当处理逻辑修改的时候，都需要重写代码，并打包重新运行

### 2.2 Hive的作用
看似好像hive没什么作用，只是给hadoop套了一个壳子，数据的存储和数据的处理其实还是由hadoop执行。实际上hive通过用户输入的sql，自行实现了MapReduce的生成和处理，不需要用户手动实现底层代码。

### 2.2 元数据
通过原理图，在hive处理的第二步的时候使用了元数据（MateData），元数据实际上存储是表和文件的映射关系的数据。通过hive我们看见的是一张表，但是hadoop里面存储的是文件。当我们的sql传入hive时，如何确定这个表对应的文件是什么，字段对应是文件的哪一列.....等等这些信息都由元数据进行存储，元数据一般存储在关系型数据库。

## 三、Hive的数据模型
![Hive的数据模型](https://github.com/xujiangchen/Big-Data/blob/main/Hive/img/data-model.png)

Hive虽然是数据仓库，但是也整个模型也是可以向关系型数据库看齐，分为库，库底下有各自的表。

### 3.1 数据库
Hive的数据都是存储在hadoop的HDFS上，默认路径为`user/hive/warehouse`

所以如果hive上有个名字叫 hivetest 的数据库，它的存储路径为 `user/hive/warehouse/hivetest.db`

### 3.2 表

- hive的表和HDFS中文件的关系，存储在元数据中

如果hivetest这个数据库中有一个叫user的表，那么这个表对应的文件存在于 `user/hive/warehouse/hivetest.db/user`

### 3.3 分区

在Hive Select查询中一般会扫描整个表内容，会消耗很多时间做没必要的工作。有时候只需要扫描表中关心的一部分数据，因此建表时引入了partition概念。分区可以根据分区列的值将表分为不同的分区。

以按时间分区为例子，在HDFS上的存储样式为：
``` python
|   hivetest.db
|     |
|     ├── user
|           ├── day=20211111
|           ├── day=20211112
|           ├── day=20211113

# 具体的数据就存储在相应的分区文件夹之下
```

### 3.4 分桶
在分区的基础之上，Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也是 针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。

简单理解规则：`字段 % 桶的个数，将余数相同的数据放到同一个桶里面`

以按时间分区为例子，再按ID分桶(有3个桶)，在HDFS上的存储样式为：
```python
|   hivetest.db
|     |
|     ├── user
|           ├── day=20211111
|                 ├── BUCKET(0)
|                 ├── BUCKET(1)
|                 ├── BUCKET(2)
|           |
|           ├── day=20211112
|           ├── day=20211113
```